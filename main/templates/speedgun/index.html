<!-- templates/home.html -->
{% extends 'base.html' %}
{% block title %}Home Page{% endblock %}
{% block content %}
<head>
{% load static %}
<link href="{% static 'speedgun/style.css' %}" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.2/papaparse.min.js"></script>
<script src="https://cdn.anychart.com/releases/8.11.0/js/anychart-base.min.js"></script>
<script src="https://cdn.anychart.com/releases/8.11.0/js/anychart-heatmap.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.20.0/themes/prism.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/9000.0.1/components/prism-python.min.js">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.20.0/prism.min.js"></script>
</head>
<body>
  <p class = "main_header">Building a tennis ball speed gun</p>
  <h1 class = "nonmainbody">The journey so far... </h1>
  <section>
    <div class="container reveal">
      <img src="{% static 'speedgun/fed.JPG' %}" alt="serve" class="responsive-image">
    </div>
  </section>
  <section>
    <div class="container reveal">
      <h1 class = "nonmainbody">What is this project? </h1>
      <div class="text-container">
        
        <img src="{% static 'tennis/logo.jpg' %}" alt="atplogo" class="mini-logo">
        <ul>
          <li class="mainlist" style="font-size:1.6em;">In March 2025, I posed a simple question - <i><b>how fast is my serve speed?</b> </i></li>
          <li class="mainlist" style="font-size:1.6em;" >As a recreational player, advanced sport statistics are often a helpful method of tracking progress. </li>
          <li class="mainlist" style="font-size:1.6em;">Tennis ball speeds are usually measured with radar guns. Radar guns accurately measure ball speeds but require installation at courts and are usually exclusive to the pro-level ATP and WTA tours.  </li>
          <li class="mainlist" style="font-size:1.6em;">So how can the average recreational player track ball speeds? </li>
          <li class="mainlist" style="font-size:1.6em;">I therefore embarked on a project to bring ball-tracking to everyone's smartphones. </li>
          <li class="mainlist" style="font-size:1.6em;">In this data story, I will share some of my set-up, methodology and reasoning in this project as I near a first prototype for a mobile tennisball speed gun. </li>
          <li class="mainlist" style="font-weight:bold;font-size:1.6em;">Scroll on to reveal how I reached this stage... </li>
        </ul>
      </div>
    </div>
  </section>
  
  <section>
    <div class="container reveal">
      <p> Click to expand:</p>
      <button type="button" class="collapsible coll2"><h1>Early experiments with Open-CV</h1></button>
      <div class="collapsecontent coll2">
        <div class = "text-container">
        <img src="{% static 'speedgun/serve1.gif' %}" alt="serve" class="mini-logo2">
        <ul>
          <li class="mainlist" style="font-size:1.6em;">To begin with, I used Open-CV: the primary choice for programmatic processing of a user's recorded video. </li>
          <li class="mainlist" style="font-size:1.6em;">I utilised basic colour and shape matching to track tennis balls in the video. </li>
          <li class="mainlist" style="font-size:1.6em;">This method is limited by the camera being a set distance away and under optimal lighting (so the ball actually appears yellow/green).</li>
          <li class="mainlist" style="font-size:1.6em;">Ball position was measured relative to the top left corner of the frame (so no measurements in real-life meters could be taken).</li>
          <li class="mainlist" style="font-size:1.6em;">The ball position was only detected using contour recognition. As the ball accelerates out of the frame this method is unable to detect it - making speed calculations impossible.</li>

        </ul>
        </div>
      </div>
  </section>
  <section>
    <div class="container reveal">
       <h1>Drawbacks of initial object detection methods</h1>
      <div class = "text-container">
       <p> The figure here highlights the issues encountered by colour and shape based detection methods alone. Objects of different sizes may seem incorrect but tennis balls may blur and deform on impact whilst any pipeline must be able to handle balls under different light conditions when they do not appear luminous green/yellow. </p>
      <img src="{% static 'speedgun/match_crit.JPG' %}" alt="serve" class="mini-logo3">
      </div>
      
    </div>
  </section>
  <section>
    <div class="container reveal">
      <button type="button" class="collapsible coll2"><h1>Developing Depth Perception</h1></button>
      <div class="collapsecontent coll2">
        <div class = "text-container">
        <img src="{% static 'speedgun/depth.gif' %}" alt="serve" class="mini-logo2">
        <ul>
          <li class="mainlist" style="font-size:1.6em;">Based on my open cv experimentations, I realised that I needed to improve two things: <b>(1)</b> Real life distance tracking <b>(2)</b> Improved ball recognition </li>
          <li class="mainlist" style="font-size:1.6em;">To overcome (1), I utilised reference images for the ball. I designed a python interface allowing users to upload an image containing a ball and to specify how far that ball was from the camera - in cm. </li>
          <li class="mainlist" style="font-size:1.6em;">Overcoming (2) was slightly more challenging. I needed to use a more sensitive and adjustable model to track the ball at different distances and under different lighting conditions.</li>
          <li class="mainlist" style="font-size:1.6em;">I therefore built a simple YOLOv5 model which was specifically tasked with tennis ball object recognition.</li>
          <li class="mainlist" style="font-size:1.6em;">The GIF here demonstrates the ability to detect the tennis ball and to track distances of both a human frontal face and the tennis ball.</li>

        </ul>
        </div>
      </div>
  </section>
  <section>
    <div class="container reveal">
       <h1>Drawbacks of initial object detection methods</h1>
      <div class = "text-container">
      <img src="{% static 'speedgun/calc.PNG' %}" alt="serve" class="mini-logo3">
             <p> The figure here displays the physics-informed calculations used to determine ball depth away from camera using a reference ball image and known ball diameter. </p>

      </div>
      
    </div>
  </section>
  <section>
    <div class="container reveal">
      <button type="button" class="collapsible coll2"><h1>Measuring real distances</h1></button>
      <div class="collapsecontent coll2">
        <div class = "text-container">
        <img src="{% static 'speedgun/groundie1.gif' %}" alt="serve" class="mini-logo2">
        <ul>
          <li class="mainlist" style="font-size:1.6em;">Building on the progress made in measuring distances and depth, I considered how best to track real-life distances. </li>
          <li class="mainlist" style="font-size:1.6em;">I realised that I needed a reference object of known dimensions in the frame in order to extrapolate distances in the frame. </li>
          <li class="mainlist" style="font-size:1.6em;">By repurposing an old shoe box, I made a distinctive yellow diamond on a white background. I then trained a YOLO detection model in YOLO v8 to explicitly detect both the tennis ball and origin box.</li>
          <li class="mainlist" style="font-size:1.6em;">The GIF here demonstrates the ability to detect the tennis ball and to track distances within its frame of travel. The YOLO model also provides confidence scores that the object detected is correct, so the each object is also annotated with a label and confidence score.</li>

        </ul>
        </div>
      </div>
  </section>
    <section>
    <div class="container reveal">
       <h1>Constructing Origin</h1>
      <div class = "text-container">
       <p> Using the origin box shown in the picture here, I was able to contstruct a reference detection point in every frame. Using its known horizontal and vertical dimensions, horizontal and vertical distance could be calculated by scaling the ball distance in pixels. This could be a sustainable way for recreational tennis players to re-use old shoeboxes in a way which improves their game at the same time. </p>
      <img src="{% static 'speedgun/origin.jpg' %}" alt="serve" class="mini-logo3">
      </div>
      
    </div>
  </section>
<section>
    <div class="container reveal">
      <button type="button" class="collapsible coll2"><h1>Measuring real distances</h1></button>
      <div class="collapsecontent coll2">
        <div class = "text-container">
        <img src="{% static 'speedgun/speed_diag.gif' %}" alt="serve" class="mini-logo2">
        <ul>
          <li class="mainlist" style="font-size:1.6em;">Now that I had the first calculations for distance, I could then begin to calculate the speed of the ball </li>
          <li class="mainlist" style="font-size:1.6em;">The method is only constrained to two dimensions (when actually balls are likely to be struck at varying depths from the camera) </li>
          <li class="mainlist" style="font-size:1.6em;">However, using the base fps (frames per second) on the original clip, I was able to calculate the distance travelled by the ball between frames and therefore provide a prediction for speed.</li>
          <li class="mainlist" style="font-size:1.6em;">The GIF here visualises the ball motion path to the shot above by modelling the ball on axes in Matplotlib.</li>

        </ul>
        </div>
      </div>
  </section>
<section>
    <div class="container reveal">
      <button type="button" class="collapsible coll2"><h1>Adjusting to faster shots</h1></button>
      <div class="collapsecontent coll2">
        <div class = "text-container">
        <img src="{% static 'speedgun/serve2.gif' %}" alt="serve" class="mini-logo2">
        <ul>
          <li class="mainlist" style="font-size:1.6em;">When balls are struck at higher speeds, the previous models have struggled to detect the ball motion.  </li>
          <li class="mainlist" style="font-size:1.6em;">Whilst the YOLO machine-learning approach improved this, lapses were still incurring at critical moments. </li>
          <li class="mainlist" style="font-size:1.6em;">I therefore added two extra safety layers. The initial layer checks for displaced pixels between frames and checks if they form an expected ball shape and size relative to what the image would expect.</li>
          <li class="mainlist" style="font-size:1.6em;">Beyond this, there is also a background-substitution layer applied to each frame to check for ball-like objects missed by previous checks.</li>
          <li class="mainlist" style="font-size:1.6em;">This leaves me with this near-perfect detection pipeline which succeeded in speed detection for a slow serve.</li>

        </ul>
        </div>
      </div>
  </section>
  
  <section>
    <div class="container reveal">
       <h1>Making it accessible</h1>
      <div class = "text-container">
       <p> By combining my pipeline with Flask and a JavaScript front-end interface, I was able to create a simple website to make the pipeline accessible. By structuring the project as a microservice, I was able to deploy it successfully via a dockerised container. I have not yet made the full container publicly available due to resource limitations.</p>
      <video width="75%" height="auto" controls>
  <source src="{% static 'speedgun/ExampleClip.mp4' %}" type="video/mp4" class="mini-logo3">
Your browser does not support the video tag.
</video>
      </div>
      
    </div>
  </section>
   <section>
    <div class="container reveal">
       <h1>What next?</h1>
      <div class = "text-container">
       <p> I am currently seeking project-partners to help to take this project to the next level. The base model pipeline requires additional testing and the user-interface microservice needs refining. If you have experience in python / front-end development and are interested in sports science / business development, please reach out to me on LinkedIn <a href = "https://www.linkedin.com/in/dhylanpatel/">here</a>! </p>
      
      </div>
      
    </div>
  </section>
<script src="{% static 'tennis/graph.js' %}"></script>
<script src="{% static 'generaluse/collapse.js' %}"></script>
<script src="{% static 'tennis/animate.js' %}"></script>
<script src = "{% static 'generaluse/reveal.js' %}"></script>
</body>
{% endblock %}
